{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NOTE: as of monday 6pm I stopped the scraper at artist # 203 (Homestuck), and the urls_to_scrape were saved in the data folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from selenium import webdriver\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 120416 unique records in the database now\n",
      "Total revenue: 904081.19\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('/Users/shayneufeld/Dropbox/insight/pricecamp/data/sales.csv',index_col=0)\n",
    "df = df.drop_duplicates()\n",
    "print('There are %.0f unique records in the database now' % df.shape[0])\n",
    "print('Total revenue: %.02f' % df.amount_paid_usd.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define function for opening more albums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reveal_albums(selenium_driver):    \n",
    "    #try implementing same thing for albums\n",
    "    showMore = selenium_driver.find_elements_by_css_selector('.showMore')\n",
    "    #there are 2 possible showMore buttons - for shows and for albums\n",
    "    #if there is a shows one, it comes first\n",
    "    el = []\n",
    "    if len(showMore) == 1:\n",
    "        el = showMore[0]\n",
    "    elif len(showMore) == 2:\n",
    "        el = showMore[1]\n",
    "    \n",
    "    #if there is a show more button, make sure it's 'more albums'\n",
    "    if el:\n",
    "        title = browser.title\n",
    "        text = el.find_element_by_tag_name('a').text\n",
    "        while text == 'more releases...':\n",
    "            el.click()\n",
    "            \n",
    "            if browser.title == title:\n",
    "                text = el.find_element_by_tag_name('a').text\n",
    "            else:\n",
    "                text = browser.title\n",
    "                \n",
    "    \n",
    "    return selenium_driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_albums_urls(browser,page_type='album'):\n",
    "    \n",
    "    elems = []\n",
    "    if page_type == 'album':\n",
    "        elems = browser.find_elements_by_css_selector('.trackTitle')\n",
    "    elif page_type == 'music':\n",
    "        elems = browser.find_elements_by_css_selector('.music-grid-item')\n",
    "        \n",
    "    album_names,album_urls = [],[]\n",
    "\n",
    "    for elem in elems[1:]:\n",
    "        album_names.append(elem.text)\n",
    "        album_urls.append(elem.find_element_by_tag_name('a').get_attribute('href'))\n",
    "        #print(elem.text)\n",
    "        #print(elem.find_element_by_tag_name('a').get_attribute('href'))\n",
    "\n",
    "    browser.close()\n",
    "    \n",
    "    return album_names,album_urls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get artists to scrap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "artist_names = []\n",
    "for url in urls_to_scrape.urls_to_scrape.values:\n",
    "    \n",
    "    artist_name = df[df.url==url].head(1).artist_name.values\n",
    "    \n",
    "    if not artist_name:\n",
    "        artist_name = df[df.url==url[6:]].head(1).artist_name.values\n",
    "\n",
    "    if type(artist_name) is not str:\n",
    "        artist_name = artist_name[0]\n",
    "        \n",
    "    artist_names.append(artist_name)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## determine URLs already scraped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "folder = '/Users/shayneufeld/Dropbox/insight/pricecamp/data/albums_supporters'\n",
    "files = os.listdir(folder)\n",
    "urls_scraped = []\n",
    "urls_0_supp = []\n",
    "for file in files:\n",
    "    if not file[0] == '.':\n",
    "        d = pd.read_csv(os.path.join(folder,file),nrows = 1)\n",
    "        if d.shape[0] > 0:\n",
    "            urls_scraped.append(d.album_url.values[0])\n",
    "        else:\n",
    "            urls_0_supp.append(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# the scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/shayneufeld/GitHub/pricecamp/scrapers/bandcamp_spider\n"
     ]
    }
   ],
   "source": [
    "cd '/Users/shayneufeld/github/pricecamp/scrapers/bandcamp_spider'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "urls_df = pd.DataFrame(data={'urls_to_scrape':urls_to_scrape})\n",
    "urls_df.to_csv('/Users/shayneufeld/Dropbox/insight/pricecamp/data/urls_to_scrape_0731_6pm.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## again - as said before. as of 6pm i stopped it at artist 203 (homestuck) and saved the csv above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls_to_scrape = pd.read_csv('/Users/shayneufeld/Dropbox/insight/pricecamp/data/urls_to_scrape_0731_6pm.csv')\n",
    "urls_to_scrape = urls_to_scrape.urls_to_scrape.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([338]),)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(urls_to_scrape=='//fullplate.bandcamp.com/album/fp009-black-tie-affair-2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "//tysegall.bandcamp.com/album/manipulator\n",
      "//teramelos.bandcamp.com/album/drugs-complex\n",
      "//uncledane.bandcamp.com/album/darn\n",
      "//goat.bandcamp.com/album/requiem\n",
      "//marketsquarerecordings.bandcamp.com/album/real-numbers-frank-infatuation-b-w-leave-it-behind\n",
      "//meteormusic.bandcamp.com/album/inner-demon\n",
      "//sugarcreamgenso.bandcamp.com/album/rhapsody-ep\n",
      "//mhysa301.bandcamp.com/album/fantasii\n",
      "//airospace.bandcamp.com/album/nocturne-2\n",
      "//sinmara.bandcamp.com/album/within-the-weaves-of-infinity\n",
      "//entheois.bandcamp.com/album/lucid-surrender-vol-2\n"
     ]
    }
   ],
   "source": [
    "error_urls = []\n",
    "\n",
    "for artist_url,artist_name in zip(urls_to_scrape[339:],artist_names[339:]):\n",
    "    '''\n",
    "    get input parameters\n",
    "    '''\n",
    "    if (('records' in artist_url) or ('productions' in artist_url)):\n",
    "        print('%s appears to be a label, not an artist' % artist_url)\n",
    "    else:\n",
    "        print(artist_url)\n",
    "        if artist_url[0] == 'h':\n",
    "            curr_url = artist_url\n",
    "        elif artist_url[0] == '/':\n",
    "            curr_url = 'https:' + artist_url\n",
    "        else:\n",
    "            print('URL BROKEN')\n",
    "\n",
    "        #get list of albums and urls to go through for this artist\n",
    "        browser = webdriver.Firefox()\n",
    "        browser.get(curr_url)\n",
    "        browser_title = browser.title\n",
    "\n",
    "        #try to clicking throuhg more albums\n",
    "        browser = reveal_albums(browser)\n",
    "\n",
    "        #if it went to the music page, the title should have changed\n",
    "        DO_NOT_SCRAPE = False\n",
    "        if browser.title == browser_title: #then we are on the same page\n",
    "            album_names,album_urls = get_albums_urls(browser,page_type='album')\n",
    "        elif 'Music' in browser.title:\n",
    "            album_names,album_urls = get_albums_urls(browser,page_type='music')\n",
    "        else:\n",
    "            DO_NOT_SCRAPE = True\n",
    "            print('ERROR - page not album or music type: %s' % artist_url)\n",
    "\n",
    "        if not DO_NOT_SCRAPE:\n",
    "            if album_urls:\n",
    "                if len(album_urls) > 10:\n",
    "                    album_urls = album_urls[:11]\n",
    "                for url in album_urls:\n",
    "                    if not url in urls_scraped:\n",
    "                        os.system(\"scrapy crawl bandcamp -a start_urls='%s'\" % (str(url)))\n",
    "                    else:\n",
    "                        print('%s already scraped' % url)\n",
    "            else:\n",
    "                print('ERROR - no album urls: %s' % artist_url)\n",
    "                error_urls.append(artist_url)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
